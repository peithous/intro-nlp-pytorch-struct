{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchtext.data as data\n",
    "from torchtext.data import BucketIterator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_struct import HMM, LinearChainCRF\n",
    "import matplotlib.pyplot as plt\n",
    "# from torch_struct.data import ConllXDatasetPOS\n",
    "\n",
    "# start_time = time.time()\n",
    "device='cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConllXDataset(data.Dataset):\n",
    "    def __init__(self, path, fields, encoding=\"utf-8\", separator=\"\\t\", **kwargs):\n",
    "        examples = []\n",
    "        columns = [[], []]\n",
    "        column_map = {1: 0, 3: 1}\n",
    "        with open(path, encoding=encoding) as input_file:\n",
    "            for line in input_file:\n",
    "                line = line.strip()\n",
    "                if line == \"\":\n",
    "                    examples.append(data.Example.fromlist(columns, fields))\n",
    "                    columns = [[], []]\n",
    "                else:\n",
    "                    for i, column in enumerate(line.split(separator)):\n",
    "#                         print(columns)\n",
    "                        if i in column_map and column !=',':\n",
    "                            columns[column_map[i]].append(column)\n",
    "            examples.append(data.Example.fromlist(columns, fields))\n",
    "        super(ConllXDataset, self).__init__(examples, fields, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total train sentences 1186\n",
      "total test sentences 45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ConllXDataset at 0x12e1e8690>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORD = data.Field(init_token='<bos>', pad_token=None, eos_token='<eos>') #init_token='<bos>', \n",
    "POS = data.Field(init_token='<bos>', include_lengths=True, pad_token=None, eos_token='<eos>') \n",
    "\n",
    "fields = (('word', WORD), ('pos', POS), (None, None))\n",
    "train = ConllXDataset('/Users/sofia/nlp-pytorch-struct/data/wsj.train0.conllx', fields, \n",
    "                filter_pred=lambda x: len(x.word) < 50) #en_ewt-ud-train.conllu\n",
    "test = ConllXDataset('/Users/sofia/nlp-pytorch-struct/data/wsj.test0.conllx', fields)\n",
    "print('total train sentences', len(train))\n",
    "print('total test sentences', len(test))\n",
    "\n",
    "WORD.build_vocab(train) # \n",
    "POS.build_vocab(train, min_freq = 5, max_size=7)\n",
    "train_iter = BucketIterator(train, batch_size=20, device=device, shuffle=False)\n",
    "test_iter = BucketIterator(test, batch_size=20, device=device, shuffle=False)\n",
    "\n",
    "C = len(POS.vocab)\n",
    "V = len(WORD.vocab)\n",
    "train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vars(train).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vars(train.examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD.vocab.freqs[',']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD.vocab.stoi['.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max(WORD.vocab.freqs, key = lambda k : WORD.vocab.freqs.get(k))\n",
    "sorted(WORD.vocab.freqs, key=WORD.vocab.freqs.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD.vocab.itos[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vars(WORD.vocab).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(set(WORD.vocab.itos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(WORD.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vars(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = next(iter(train_iter))\n",
    "# batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch.word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label, lengths = batch.pos\n",
    "# lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for b in range(batch.word.shape[1]):\n",
    "#     print(batch.word[:lengths[b], b], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cbow_data = []\n",
    "# for ex in train_iter:\n",
    "# #    print(ex.pos)\n",
    "#     words = ex.word\n",
    "#     label, lengths = ex.pos\n",
    "    \n",
    "#     for b in range(ex.word.shape[1]):\n",
    "#         for i in range(2, lengths[b]-2):\n",
    "#             context = torch.stack((ex.word[i-2, b], ex.word[i-1, b], ex.word[i+1, b], ex.word[i+2, b]))\n",
    "#             target = ex.word[i, b]\n",
    "#             cbow_data.append((context, target))\n",
    "# cbow_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMDEDDING_DIM = 100\n",
    "\n",
    "class CBOW(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(CBOW, self).__init__()\n",
    "        \n",
    "        #out: 1 x emdedding_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(embedding_dim, 128)\n",
    "        self.activation_function1 = nn.ReLU()       \n",
    "        #out: 1 x vocab_size\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "        self.activation_function2 = nn.LogSoftmax(dim = -1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        embeds = sum(self.embeddings(inputs)).view(1,-1)\n",
    "        out = self.linear1(embeds)\n",
    "        out = self.activation_function1(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.activation_function2(out)\n",
    "        return out\n",
    "\n",
    "model = CBOW(V, EMDEDDING_DIM)\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_data = []\n",
    "for ex in train_iter:\n",
    "#    print(ex.pos)\n",
    "    words = ex.word\n",
    "    _, lengths = ex.pos\n",
    "    \n",
    "    for b in range(ex.word.shape[1]):\n",
    "        for i in range(2, lengths[b]-2):\n",
    "            context = torch.stack((ex.word[i-2, b], ex.word[i-1, b], ex.word[i+1, b], ex.word[i+2, b]))\n",
    "            target = ex.word[i, b].unsqueeze(0)\n",
    "            cbow_data.append((context, target))\n",
    "cbow_data\n",
    "\n",
    "for epoch in range(1):\n",
    "    total_loss = 0\n",
    "\n",
    "    for context, target in cbow_data:\n",
    "\n",
    "        log_probs = model(context)\n",
    "        total_loss += loss_function(log_probs, target)\n",
    "\n",
    "    #optimize at the end of each epoch\n",
    "    optimizer.zero_grad()\n",
    "    total_loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=model(cbow_data[19][0])\n",
    "b=model(cbow_data[40][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD.vocab.itos[torch.argmax(b[0]).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join([WORD.vocab.itos[i] for i in cbow_data[40][0]]))\n",
    "print([WORD.vocab.itos[cbow_data[40][1]]] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts for mle's \n",
    "tags = [] # prior\n",
    "bigrams = [] # transition\n",
    "word_tag_counts = [] # emission\n",
    "for ex in train_iter:\n",
    "#    print(ex.pos)\n",
    "    words = ex.word\n",
    "    label, lengths = ex.pos\n",
    "    for batch in range(label.shape[1]):\n",
    "    #    print(' '.join([WORD.vocab.itos[i] for i in words[:lengths[batch], batch]]))        \n",
    "        tags.append(label[:lengths[batch], batch])\n",
    "        bigrams.append(label[:lengths[batch], batch].unfold(0, 2, 1)) #dimension, size, step      \n",
    "        for i, t in enumerate(label[:lengths[batch], batch]):\n",
    "            word_tag_counts.append(torch.tensor((t.item(), words[i, batch].item())))\n",
    "tags = torch.cat(tags, 0)\n",
    "bigrams = torch.cat(bigrams, 0)\n",
    "word_tag_counts = torch.stack(word_tag_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior\n",
    "init = torch.ones(C).long() # add-1 smoothing\n",
    "init.index_put_((tags,), torch.tensor(1), accumulate=True)\n",
    "assert init[POS.vocab.stoi['<eos>']] == len(train)+1\n",
    "init = init.float() / init.sum()\n",
    "assert torch.isclose(init.sum(), torch.tensor(1.))# \\sum_C p_c = 1\n",
    "init = init.log()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transition\n",
    "transition = torch.ones((C, C)).long() # p(. | eos) = 1/C\n",
    "transition.index_put_((bigrams[:, 0], bigrams[:, 1]), torch.tensor(1), accumulate=True)\n",
    "transition = (transition.float() / transition.sum(-1, keepdim=True)).transpose(0, 1) \n",
    "assert torch.isclose(transition.sum(0, keepdim=True).sum(), \\\n",
    "        torch.tensor(C, dtype=torch.float)) # should be for x in C-{eos}, sum_C  p(c, x) = 1?\n",
    "transition = transition.log()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emission \n",
    "emission = torch.ones((C, V)).long()\n",
    "emission.index_put_((word_tag_counts[:, 0], word_tag_counts[:, 1]), torch.tensor(1), accumulate=True)\n",
    "emission = (emission.float() / emission.sum(-1, keepdim=True)).transpose(0, 1)\n",
    "assert torch.isclose(emission.sum(0, keepdim=True).sum(), \\\n",
    "        torch.tensor(C, dtype=torch.float)) # sum_V p(v | c) = 1\n",
    "emission = emission.log()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "observations = torch.LongTensor(next(iter(test_iter)).word).transpose(0, 1).contiguous()    \n",
    "observations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = torch.zeros(20, 43, C, C).type_as(emission)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores += transition.view(1, 1, C, C)\n",
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = emission[observations.view(20*44), : ]\n",
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.view(20, 44, C, 1)[:, 1:].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.view(20, 44, 1, C)[:, 0].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_chain(chain):\n",
    "    plt.imshow(chain.detach().sum(-1).transpose(0, 1))\n",
    "\n",
    "# print('t1', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(iters):\n",
    "    losses = []\n",
    "    total = 0\n",
    "    incorrect_edges = 0 \n",
    "    #model.eval()\n",
    "    for i, ex in enumerate(iters):      \n",
    "        observations = torch.LongTensor(ex.word).transpose(0, 1).contiguous()            \n",
    "        label, lengths = ex.pos\n",
    "        \n",
    "#         print(transition)\n",
    "        dist = HMM(transition, emission, init, observations, lengths=lengths) \n",
    "        labels = LinearChainCRF.struct.to_parts(label.transpose(0, 1) \\\n",
    "                .type(torch.LongTensor), C, lengths=lengths).type(torch.FloatTensor)    \n",
    "        # print(HMM.struct.from_parts(dist.argmax)[0][0])\n",
    "        # print('label', labels.shape)  \n",
    "        # print(dist.argmax.shape)\n",
    "        # show_chain(dist.argmax[0])  \n",
    "        # plt.show()\n",
    "\n",
    "        loglik = dist.log_prob(labels).sum()\n",
    "        # print(loglik, label.shape[1])\n",
    "        losses.append(loglik.detach()/label.shape[1])\n",
    "\n",
    "        incorrect_edges += (dist.argmax.sum(-1) - labels.sum(-1)).abs().sum() / 2.0\n",
    "        total += dist.argmax.sum()         \n",
    "\n",
    "    print(total, incorrect_edges)\n",
    "    print('inaccurate', incorrect_edges / total) \n",
    "    return torch.tensor(losses).mean()\n",
    "\n",
    "# print('train-log-lik', test(train_iter))\n",
    "print('test-log-lik', test(test_iter))\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print(transition,\"\\n\", emission,\"\\n\", init )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.tensor([[1, 2], [3, 4]])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(((1, 2), (3, 4))).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r = torch.randint(0, 9, (2, 3, 4, 4))\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[:, 1:, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
