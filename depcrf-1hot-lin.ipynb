{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_struct import DependencyCRF\n",
    "import torch_struct.data \n",
    "import torchtext.data as data\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_num(nums):\n",
    "    lengths = torch.tensor([len(n) for n in nums]).long()\n",
    "    n = lengths.max()\n",
    "    out = torch.zeros(len(nums), n).long()\n",
    "    for b, n in enumerate(nums):\n",
    "        out[b, :len(n)] = torch.tensor(n)\n",
    "    return out, lengths\n",
    "HEAD = data.RawField(preprocessing= lambda x: [int(i) for i in x],\n",
    "                     postprocessing=batch_num, \n",
    "                     is_target = True)\n",
    "WORD = data.Field(pad_token=None)\n",
    "train = torch_struct.data.ConllXDataset(\"wsj.train0.conllx\", (('word', WORD), ('head', HEAD)),\n",
    "                     ) #filter_pred=lambda x: 5 < len(x.word) < 40\n",
    "val = torch_struct.data.ConllXDataset(\"wsj.train0.conllx\", (('word', WORD), ('head', HEAD)),\n",
    "                     ) #  filter_pred=lambda x: 5 < len(x.word[0]) < 40\n",
    "WORD.build_vocab(train)\n",
    "train_iter = data.BucketIterator(train, batch_size=2, device='cpu', shuffle=False)\n",
    "val_iter = data.BucketIterator(val, batch_size=2, device=\"cpu\", shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = len(WORD.vocab.itos)\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, hidden):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.eye(V).type(torch.FloatTensor), freeze=True) #one hot \n",
    "        # F.one_hot(torch.arange(V))\n",
    "        self.linear = nn.Linear(V, V)\n",
    "        self.bilinear = nn.Linear(V, V)\n",
    "\n",
    "        self.root = nn.Parameter(torch.rand(V))\n",
    "        \n",
    "    def forward(self, words):\n",
    "        out = self.embedding(words) # (b x N ) -> (b x N x V)\n",
    "#         final2 = self.linear(out) # (b x N x V) (V x V) -> (b x N x V)\n",
    "#         final = torch.einsum(\"bnh,hg,bmg->bnm\", out, self.bilinear.weight, final2) # (N x V) (V x V) (N x V)^T -> (N, N)\n",
    "#         #print('ein3', final.shape)\n",
    "        \n",
    "        final = torch.einsum(\"bnh,hg,bmg->bnm\", out, self.linear.weight, out)\n",
    "        #print(final.shape)\n",
    "        root_score = torch.einsum(\"bnh,h->bn\", out, self.root) # (N x V) x V -> N\n",
    "        #print('root', root_score)\n",
    "\n",
    "        N = final.shape[1]\n",
    "        final[:, torch.arange(N), torch.arange(N)] += root_score\n",
    "        #print('f2', final.shape)\n",
    "        return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 tensor(65.6041) torch.Size([2, 17])\n",
      "tensor(276.) tensor(252.)\n",
      "6 tensor(63.4083) torch.Size([2, 17])\n",
      "tensor(276.) tensor(236.)\n",
      "6 tensor(58.3279) torch.Size([2, 17])\n",
      "tensor(276.) tensor(220.)\n",
      "6 tensor(51.0446) torch.Size([2, 17])\n",
      "tensor(276.) tensor(139.)\n"
     ]
    }
   ],
   "source": [
    "model = Model(V)\n",
    "opt = optim.SGD(model.parameters(), lr=1e-4)\n",
    "\n",
    "def show_deps(tree):\n",
    "    plt.imshow(tree.detach())\n",
    "\n",
    "def validate(val_iter):\n",
    "    incorrect_edges = 0\n",
    "    total_edges = 0\n",
    "    model.eval()\n",
    "    for i, ex in enumerate(val_iter):\n",
    "        words = ex.word.transpose(0,1)\n",
    "        label, lengths = ex.head\n",
    "\n",
    "        final = model(words) #.cuda()\n",
    "\n",
    "        dist = DependencyCRF(final, lengths=lengths)\n",
    "        argmax = dist.argmax\n",
    "        gold = dist.struct.to_parts(label, lengths=lengths).type_as(argmax)\n",
    "        incorrect_edges += (argmax[:, :].cpu() - gold[:, :].cpu()).abs().sum() / 2.0\n",
    "        total_edges += gold.sum()\n",
    "\n",
    "        gold1 = DependencyCRF(gold, lengths=lengths)\n",
    "\n",
    "    print(total_edges, incorrect_edges)   \n",
    "    model.train()\n",
    "    return gold1\n",
    "\n",
    "def trn(train_iter, model):\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        losses = []\n",
    "\n",
    "        for i, ex in enumerate(train_iter):\n",
    "            #print(i)\n",
    "            # print(ex.word.shape) # sq x b\n",
    "            # print(ex.head[0].shape) # b x sq\n",
    "            # print('lens', ex.head[1])\n",
    "            \n",
    "            words = ex.word.transpose(0,1)\n",
    "            label, lengths = ex.head\n",
    "            #batch, _ = label.shape\n",
    "            \n",
    "            final = model(words)\n",
    "            #print(model.embedding.weight)\n",
    "            #print(final)\n",
    "            dist = DependencyCRF(final, lengths=lengths)\n",
    "            # dist.multiroot=False\n",
    "\n",
    "            labels = dist.struct.to_parts(label, lengths=lengths).type_as(final)\n",
    "            #print('labels', labels.shape)\n",
    "\n",
    "            log_prob = dist.log_prob(labels)\n",
    "            #print(log_prob.shape)\n",
    "\n",
    "            loss = log_prob.sum()\n",
    "            (-loss).backward()\n",
    "            losses.append(loss.detach())\n",
    "            opt.step()\n",
    "\n",
    "        if epoch % 10 == 1:            \n",
    "            print(i, -torch.tensor(losses).mean(), words.shape)\n",
    "            losses = []\n",
    "            # show_deps(dist.argmax[0])\n",
    "            # plt.show()\n",
    "            \n",
    "        if epoch % 10 == 1:\n",
    "            gold = validate(val_iter)        \n",
    "            # show_deps(gold.argmax[0])\n",
    "            # plt.show()\n",
    "\n",
    "trn(train_iter, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
