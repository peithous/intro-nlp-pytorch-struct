{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchtext.data as data\n",
    "from torchtext.data import BucketIterator\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch_struct import LinearChainCRF\n",
    "#import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ConllXDataset(data.Dataset):\n",
    "    def __init__(self, path, fields, encoding='utf-8', separator='\\t', **kwargs):\n",
    "        examples = []\n",
    "        columns = [[], []]\n",
    "        column_map = {1: 0, 3: 1}\n",
    "        with open(path, encoding=encoding) as input_file:\n",
    "            for line in input_file:\n",
    "                line = line.strip()\n",
    "                if line == '':\n",
    "                    examples.append(data.Example.fromlist(columns, fields))\n",
    "                    columns = [[], []]\n",
    "                else:\n",
    "                    for i, column in enumerate(line.split(separator)):\n",
    "                        if i in column_map:\n",
    "                            columns[column_map[i]].append(column)\n",
    "            examples.append(data.Example.fromlist(columns, fields))\n",
    "        super(ConllXDataset, self).__init__(examples, fields, **kwargs)\n",
    "\n",
    "#to do: add bos\n",
    "WORD = data.Field(pad_token=None) # init_token='<bos>', eos_token='<eos>'\n",
    "POS = data.Field(is_target=True,  include_lengths=True)\n",
    "\n",
    "fields = (('word', WORD), ('pos', POS), (None, None))\n",
    "train = ConllXDataset('samIam.conllu', fields)\n",
    "test = ConllXDataset('test.conllu', fields)\n",
    "\n",
    "WORD.build_vocab(train)\n",
    "POS.build_vocab(train)\n",
    "#print(vars(POS.vocab))\n",
    "\n",
    "train_iter = BucketIterator(train, batch_size=2, device='cpu', shuffle=False)\n",
    "test_iter = BucketIterator(test, batch_size=2, device='cpu', shuffle=False)\n",
    "\n",
    "C = len(POS.vocab.itos)\n",
    "V = len(WORD.vocab.itos)\n",
    "C, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'freqs': Counter({'PRON': 7, 'AUX': 7, 'PUNCT': 7, 'PROPN': 4, '<unk>': 2}), 'itos': ['<unk>', '<pad>', 'AUX', 'PRON', 'PUNCT', 'PROPN'], 'unk_index': 0, 'stoi': defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x127e82210>>, {'<unk>': 0, '<pad>': 1, 'AUX': 2, 'PRON': 3, 'PUNCT': 4, 'PROPN': 5}), 'vectors': None}\n"
     ]
    }
   ],
   "source": [
    "print(vars(POS.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, voc_size, num_pos_tags):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.eye(voc_size).type(torch.FloatTensor), freeze=True) #one hot \n",
    "        self.linear = nn.Linear(voc_size, num_pos_tags) # batch x C x V -> batch x C_t x C_t-1\n",
    "        self.transition = nn.Linear(num_pos_tags, num_pos_tags)\n",
    "        \n",
    "    def forward(self, words):\n",
    "        out = self.embedding(words) # (b x N ) -> (b x N x V)\n",
    "        final = self.linear(out) # (b x N x V) (V x C) -> (b x N x C)\n",
    "        batch, N, C = final.shape\n",
    "        vals = final.view(batch, N, C, 1)[:, 1:N] + self.transition.weight.view(1, 1, C, C)\n",
    "        vals[:, 0, :, :] += final.view(batch, N, 1, C)[:, 0] \n",
    "        return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-13.8836)\n",
      "tensor(-13.4600)\n",
      "tensor(-13.0552)\n",
      "tensor(-12.6687)\n",
      "tensor(-12.2995)\n",
      "tensor(-11.9471)\n",
      "tensor(-11.6107)\n",
      "tensor(-11.2897)\n",
      "tensor(-10.9835)\n",
      "tensor(-10.6913)\n",
      "tensor(-10.4127)\n",
      "tensor(-10.1470)\n",
      "tensor(-9.8936)\n",
      "tensor(-9.6519)\n",
      "tensor(-9.4213)\n",
      "tensor(-9.2012)\n",
      "tensor(-8.9912)\n",
      "tensor(-8.7905)\n",
      "tensor(-8.5988)\n",
      "tensor(-8.4155)\n",
      "tensor(-8.2401)\n",
      "tensor(-8.0723)\n",
      "tensor(-7.9114)\n",
      "tensor(-7.7572)\n",
      "tensor(-7.6092)\n",
      "tensor(-7.4671)\n",
      "tensor(-7.3305)\n",
      "tensor(-7.1991)\n",
      "tensor(-7.0727)\n",
      "tensor(-6.9509)\n",
      "tensor(-6.8335)\n",
      "tensor(-6.7202)\n",
      "tensor(-6.6108)\n",
      "tensor(-6.5051)\n",
      "tensor(-6.4029)\n",
      "tensor(-6.3041)\n",
      "tensor(-6.2084)\n",
      "tensor(-6.1158)\n",
      "tensor(-6.0259)\n",
      "tensor(-5.9389)\n",
      "tensor(-5.8544)\n",
      "tensor(-5.7724)\n",
      "tensor(-5.6928)\n",
      "tensor(-5.6154)\n",
      "tensor(-5.5402)\n",
      "tensor(-5.4672)\n",
      "tensor(-5.3961)\n",
      "tensor(-5.3270)\n",
      "tensor(-5.2597)\n",
      "tensor(-5.1942)\n",
      "tensor(-5.1304)\n",
      "tensor(-5.0683)\n",
      "tensor(-5.0079)\n",
      "tensor(-4.9489)\n",
      "tensor(-4.8915)\n",
      "tensor(-4.8355)\n",
      "tensor(-4.7810)\n",
      "tensor(-4.7278)\n",
      "tensor(-4.6759)\n",
      "tensor(-4.6253)\n",
      "tensor(-4.5759)\n",
      "tensor(-4.5278)\n",
      "tensor(-4.4808)\n",
      "tensor(-4.4350)\n",
      "tensor(-4.3903)\n",
      "tensor(-4.3467)\n",
      "tensor(-4.3041)\n",
      "tensor(-4.2625)\n",
      "tensor(-4.2220)\n",
      "tensor(-4.1824)\n",
      "tensor(-4.1437)\n",
      "tensor(-4.1059)\n",
      "tensor(-4.0691)\n",
      "tensor(-4.0331)\n",
      "tensor(-3.9979)\n",
      "tensor(-3.9636)\n",
      "tensor(-3.9300)\n",
      "tensor(-3.8972)\n",
      "tensor(-3.8652)\n",
      "tensor(-3.8340)\n",
      "tensor(-3.8034)\n",
      "tensor(-3.7735)\n",
      "tensor(-3.7444)\n",
      "tensor(-3.7158)\n",
      "tensor(-3.6880)\n",
      "tensor(-3.6607)\n",
      "tensor(-3.6341)\n",
      "tensor(-3.6080)\n",
      "tensor(-3.5826)\n",
      "tensor(-3.5577)\n",
      "tensor(-3.5333)\n",
      "tensor(-3.5095)\n",
      "tensor(-3.4862)\n",
      "tensor(-3.4634)\n",
      "tensor(-3.4411)\n",
      "tensor(-3.4193)\n",
      "tensor(-3.3979)\n",
      "tensor(-3.3770)\n",
      "tensor(-3.3566)\n",
      "tensor(-3.3365)\n"
     ]
    }
   ],
   "source": [
    "model = Model(V, C)\n",
    "opt = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "def trn(train_iter):\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "#        losses = []\n",
    "        for i, batch in enumerate(train_iter):\n",
    "            #model.zero_grad()\n",
    "            #print(i)\n",
    "            opt.zero_grad() \n",
    "            \n",
    "            sents = batch.word.transpose(0,1)\n",
    "            label, lengths = batch.pos\n",
    "\n",
    "            log_potentials = model(sents)\n",
    "\n",
    "            dist = LinearChainCRF(log_potentials, lengths=lengths) # f(y) = \\prod_{n=1}^N \\phi(n, y_n, y_n{-1}) \n",
    "            #print('d', dist.marginals.shape, dist.marginals)\n",
    "            #print(dist.argmax.shape) \n",
    "            #show_chain(dist.argmax[0])\n",
    "            #plt.show()\n",
    "\n",
    "            labels = LinearChainCRF.struct.to_parts(label.transpose(0, 1) \\\n",
    "                        .type(torch.LongTensor), C, lengths=lengths).type(torch.FloatTensor) # b x N x C -> b x (N-1) x C x C \n",
    "            #print('l', labels.shape) #labels\n",
    "            \n",
    "            #print(dist.log_prob(labels))\n",
    "\n",
    "            loss = dist.log_prob(labels).sum() # (*sample_shape x batch_shape x event_shape*) -> (*sample_shape x batch_shape*)\n",
    "            #print(loss)\n",
    "\n",
    "            (-loss).backward()\n",
    "            opt.step()\n",
    "            #losses.append(loss.detach())\n",
    "\n",
    "        #print(sum(losses))\n",
    "           \n",
    "        test_losses = []\n",
    "        for i, batch in enumerate(test_iter):\n",
    "            model.eval()\n",
    "\n",
    "            sents = batch.word.transpose(0,1)\n",
    "            label, lengths = batch.pos\n",
    "\n",
    "            log_potentials = model(sents)\n",
    "                    #print(probs.shape)\n",
    "                    #for param in model.parameters():\n",
    "                    #    print(i, param) \n",
    "            dist = LinearChainCRF(log_potentials, lengths=lengths) \n",
    "            #print('label', label.transpose(0, 1)[0])  \n",
    "\n",
    "            #print('d', dist.marginals.shape, dist.marginals)\n",
    "            #print(dist.argmax.shape) \n",
    "\n",
    "            #show_chain(dist.argmax[0])  \n",
    "            #plt.show()\n",
    "\n",
    "            labels = LinearChainCRF.struct.to_parts(label.transpose(0, 1) \\\n",
    "                        .type(torch.LongTensor), C, lengths=lengths).type(torch.FloatTensor) # b x N x C -> b x (N-1) x C x C \n",
    "            #print('l', labels.shape, labels)\n",
    "                    \n",
    "            #print(dist.log_prob(labels))\n",
    "\n",
    "            loss = dist.log_prob(labels).sum() # (*sample_shape x batch_shape x event_shape*) -> (*sample_shape x batch_shape*)\n",
    "            test_losses.append(loss.detach())\n",
    "            #print(epoch, loss)\n",
    "            \n",
    "        print(torch.tensor(test_losses).mean())\n",
    "\n",
    "trn(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
