{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/harvardnlp/pytorch-struct/blob/master/notebooks/BertDependencies.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "dENII4iGN3S4",
    "outputId": "e87f5c44-3da0-4df4-8f8b-f91c5adbb93e"
   },
   "outputs": [],
   "source": [
    "# https://github.com/harvardnlp/pytorch-struct/blob/master/notebooks/BertTagger.ipynb\n",
    "\n",
    "# !pip install -qqq torchtext wandb\n",
    "# !pip install -qqq pytorch-transformers\n",
    "# !pip install -qqqU git+https://github.com/harvardnlp/pytorch-struct\n",
    "# !git clone -q http://github.com/srush/temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "EghAJ7aJDl4V",
    "outputId": "970f7f28-6f4a-4c80-f4c8-3b348bdbbfd7"
   },
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_struct import DependencyCRF\n",
    "import torch_struct.data\n",
    "import torchtext.data as data\n",
    "from pytorch_transformers import AdamW, WarmupLinearSchedule\n",
    "from pytorch_transformers import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "config = {\"bert\": \"bert-base-cased\", \"H\" : 768, \"dropout\": 0.2\n",
    "         }\n",
    "\n",
    "# Comment or add your wandb\n",
    "# import wandb\n",
    "# wandb.init(project=\"pytorch-struct-tagging\", config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l63Zy6ap95Ug"
   },
   "source": [
    "Parse the conll dependency data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vQoaK1lv-CXc"
   },
   "source": [
    "TorchText batching setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YsKQXHflOmDe",
    "outputId": "0d184e8e-a2a4-4c5a-830d-3d0bc96e3963"
   },
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = BertModel, BertTokenizer, config['bert']\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "WORD = torch_struct.data.SubTokenizedField(tokenizer)\n",
    "\n",
    "def batch_num(nums):\n",
    "    lengths = torch.tensor([len(n) for n in nums]).long()\n",
    "    n = lengths.max()\n",
    "    out = torch.zeros(len(nums), n).long()\n",
    "    for b, n in enumerate(nums):\n",
    "        out[b, :len(n)] = torch.tensor(n)\n",
    "    return out, lengths\n",
    "HEAD = data.RawField(preprocessing= lambda x: [int(i) for i in x],\n",
    "                     postprocessing=batch_num)\n",
    "HEAD.is_target = True\n",
    "\n",
    "train = torch_struct.data.ConllXDataset(\"wsj.train0.conllx\", (('word', WORD), ('head', HEAD), (None, None)),\n",
    "                   ) #  filter_pred=lambda x: 5 < len(x.word[0]) < 40\n",
    "#train_iter = torchtext.data.BucketIterator(train, batch_size=3, device=\"cpu\", shuffle=False)\n",
    "train_iter = torch_struct.data.TokenBucket(train, batch_size=10, device=\"cpu\")\n",
    "\n",
    "\n",
    "val = torch_struct.data.ConllXDataset(\"wsj.train0.conllx\", (('word', WORD), ('head', HEAD), (None, None)),\n",
    "                     filter_pred=lambda x: 5 < len(x.word[0]) < 40)\n",
    "val_iter = torchtext.data.BucketIterator(val, batch_size=3, device=\"cpu\", shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, x in enumerate(train_iter):\n",
    "#     print(i)\n",
    "#     print(x.word[0].shape) #word sq.s\n",
    "#     print(x.word[1].shape) #mapper : b x max_bert_tok_len x max_word_len+2 (ie bos, eos)\n",
    "#     print(x.word[2]) #bert_tok_lengths\n",
    "#     print(x.head[0].shape)\n",
    "#     print(x.head[1])\n",
    "\n",
    "# for i, x in enumerate(val_iter):\n",
    "#     print(i)\n",
    "#     print(x.word[0].shape) #word sq.s\n",
    "#     print(x.word[1].shape) #mapper : b x max_bert_tok_len x max_word_len+2\n",
    "#     print(x.word[2]) #bert_tok_lengths\n",
    "#     print(x.head[0].shape)\n",
    "#     print(x.head[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = next(iter(train_iter))\n",
    "# #y.word \n",
    "# y.word[0].shape, y.word[0][0], y.word[1].shape, y.word[1][0], y.word[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z-40o2UA-Ha7"
   },
   "source": [
    "Make a Bert model to compute the potentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "id": "QUKVqGUsSmYY",
    "outputId": "6317e23a-5ac7-45f2-9d01-2249d9675b2c"
   },
   "outputs": [],
   "source": [
    "H = config[\"H\"]\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, hidden):\n",
    "        super().__init__()\n",
    "        self.base_model = model_class.from_pretrained(pretrained_weights)\n",
    "        self.linear = nn.Linear(H, H)\n",
    "        self.bilinear = nn.Linear(H, H)\n",
    "        self.root = nn.Parameter(torch.rand(H))\n",
    "        self.dropout = nn.Dropout(config[\"dropout\"])\n",
    "        \n",
    "    def forward(self, words, mapper):\n",
    "        out = self.dropout(self.base_model(words)[0])\n",
    "        out = torch.einsum(\"bca,bch->bah\", mapper.float(), out) #.cuda()\n",
    "        final2 = torch.einsum(\"bnh,hg->bng\", out, self.linear.weight)\n",
    "        final = torch.einsum(\"bnh,hg,bmg->bnm\", out, self.bilinear.weight, final2)\n",
    "        root_score = torch.einsum(\"bnh,h->bn\", out, self.root)\n",
    "        final = final[:, 1:-1, 1:-1]\n",
    "        N = final.shape[1]\n",
    "        final[:, torch.arange(N), torch.arange(N)] += root_score[:, 1:-1]\n",
    "        return final\n",
    "\n",
    "model = Model(H)\n",
    "#wandb.watch(model)\n",
    "#model.cuda()\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "grxGRu2b-LdT"
   },
   "source": [
    "Generic training loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HENkCYOKSwHr"
   },
   "outputs": [],
   "source": [
    "def show_deps(tree):\n",
    "    plt.imshow(tree.detach())\n",
    "    \n",
    "def validate(val_iter):\n",
    "    incorrect_edges = 0\n",
    "    total_edges = 0\n",
    "    model.eval()\n",
    "    for i, ex in enumerate(val_iter):\n",
    "        words, mapper, _ = ex.word\n",
    "        label, lengths = ex.head\n",
    "        batch, _ = label.shape\n",
    "\n",
    "        final = model(words, mapper) #.cuda()\n",
    "        for b in range(batch):\n",
    "            final[b, lengths[b]-1:, :] = 0\n",
    "            final[b, :, lengths[b]-1:] = 0\n",
    "        dist = DependencyCRF(final, lengths=lengths)\n",
    "        argmax = dist.argmax\n",
    "        gold = dist.struct.to_parts(label, lengths=lengths).type_as(argmax)\n",
    "        incorrect_edges += (argmax[:, :].cpu() - gold[:, :].cpu()).abs().sum() / 2.0\n",
    "        total_edges += gold.sum()  \n",
    "\n",
    "        gold1 = DependencyCRF(gold, lengths=lengths)\n",
    "\n",
    "    print(total_edges, incorrect_edges)   \n",
    "    model.train()\n",
    "    return gold1\n",
    "\n",
    "def train(train_iter, val_iter, model):\n",
    "    opt = AdamW(model.parameters(), lr=1e-4, eps=1e-8)\n",
    "    scheduler = WarmupLinearSchedule(opt, warmup_steps=20, t_total=2500)\n",
    "    for epoch in range(50):\n",
    "        #print(epoch)\n",
    "        model.train()\n",
    "        losses = []\n",
    "\n",
    "        for i, ex in enumerate(train_iter):\n",
    "            opt.zero_grad()\n",
    "            words, mapper, _ = ex.word\n",
    "            #print(words.shape, mapper.shape)\n",
    "            label, lengths = ex.head\n",
    "            batch, _ = label.shape\n",
    "\n",
    "            # Model\n",
    "            final = model(words, mapper) #.cuda()\n",
    "            #print('final', final.shape)\n",
    "    #         for b in range(batch):\n",
    "    #             final[b, lengths[b]-1:, :] = 0\n",
    "    #             final[b, :, lengths[b]-1:] = 0\n",
    "\n",
    "    #         print(2, final.shape, final)\n",
    "\n",
    "    #       if not lengths.max() == final.shape[1]:\n",
    "            if not lengths.max() <= final.shape[1] + 1:\n",
    "                print(\"fail\")\n",
    "                continue\n",
    "\n",
    "            dist = DependencyCRF(final, lengths=lengths)\n",
    "            #print('dist', dist.argmax.shape)\n",
    "\n",
    "            labels = dist.struct.to_parts(label, lengths=lengths).type_as(final)\n",
    "            #print('labels', labels.shape)\n",
    "            log_prob = dist.log_prob(labels)\n",
    "\n",
    "            loss = log_prob.sum()\n",
    "            (-loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            opt.step()\n",
    "            scheduler.step()\n",
    "            losses.append(loss.detach())\n",
    "        #print(-torch.tensor(losses).mean())\n",
    "\n",
    "        if epoch % 10 == 1:            \n",
    "            print(i, -torch.tensor(losses).mean(), words.shape)\n",
    "            losses = []\n",
    "            show_deps(dist.argmax[0])\n",
    "            plt.show()\n",
    "            \n",
    "        if epoch % 10 == 1:\n",
    "            gold = validate(val_iter)        \n",
    "            show_deps(gold.argmax[0])\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "colab_type": "code",
    "id": "D-HW3z1VT2MG",
    "outputId": "0d7b9ef1-8c82-4c8b-c25b-4737237e02ce",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5056f3e28c15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-822a1b9364db>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_iter, val_iter, model)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                         \u001b[0mminibatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/torchtext/data/batch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, dataset, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, batch, *args, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \"\"\"\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocessing\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/intro-nlp-pytorch-struct/torch_struct/data/data.py\u001b[0m in \u001b[0;36mtoken_post\u001b[0;34m(ls)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "train(train_iter, val_iter, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Tree.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
